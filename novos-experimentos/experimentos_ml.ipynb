{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IOJzqS7fGHm7"
      },
      "source": [
        "# Treinamento de modelos de aprendizagem de máquina em classificação binária e multilabel usando o dataset ToLD-Br"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "My8FdnWjGnIv"
      },
      "source": [
        "## Imports e configurações iniciais"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ouTDORM2GFvT",
        "outputId": "67932d1b-614c-4417-b61b-3abab857579a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /home/eliane/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import re\n",
        "import string\n",
        "import unicodedata\n",
        "import json\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download(\"stopwords\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "VvcwnwBVGwm1"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics import (accuracy_score, precision_score, recall_score,\n",
        "                             f1_score, confusion_matrix, classification_report, hamming_loss)\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.multiclass import OneVsRestClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "hepjl5ING0ym"
      },
      "outputs": [],
      "source": [
        "SEED = 42\n",
        "np.random.seed(SEED)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lyDvRZweHapH"
      },
      "source": [
        "## Carregamento dos dados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "iOwlQr76Hdj_"
      },
      "outputs": [],
      "source": [
        "dataset_path = \"../ToLD-BR.csv\"\n",
        "\n",
        "df = pd.read_csv(dataset_path, encoding=\"utf-8\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "UWdA0IRUIFgX",
        "outputId": "2751c819-e214-4611-ba5c-1c5295d577aa"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>homophobia</th>\n",
              "      <th>obscene</th>\n",
              "      <th>insult</th>\n",
              "      <th>racism</th>\n",
              "      <th>misogyny</th>\n",
              "      <th>xenophobia</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Meu nivel de amizade com isis é ela ter meu in...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>rt @user @user o cara adultera dados, que fora...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>@user @user @user o cara só é simplesmente o m...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>eu to chorando vei vsf e eu nem staneio izone ...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Eleitor do Bolsonaro é tão ignorante q não per...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  homophobia  obscene  \\\n",
              "0  Meu nivel de amizade com isis é ela ter meu in...         0.0      0.0   \n",
              "1  rt @user @user o cara adultera dados, que fora...         0.0      0.0   \n",
              "2  @user @user @user o cara só é simplesmente o m...         0.0      2.0   \n",
              "3  eu to chorando vei vsf e eu nem staneio izone ...         0.0      1.0   \n",
              "4  Eleitor do Bolsonaro é tão ignorante q não per...         0.0      1.0   \n",
              "\n",
              "   insult  racism  misogyny  xenophobia  \n",
              "0     2.0     0.0       0.0         0.0  \n",
              "1     1.0     0.0       0.0         0.0  \n",
              "2     1.0     0.0       0.0         0.0  \n",
              "3     0.0     0.0       0.0         0.0  \n",
              "4     2.0     0.0       0.0         0.0  "
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KiEtrtpoG28q"
      },
      "source": [
        "## Pré processamento de dados"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aQ0Wi_yJG_vV"
      },
      "source": [
        "Remoção de acentos, URLs, menções, hashtags, dígitos e pontuação"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "nk4QaqseG6sO"
      },
      "outputs": [],
      "source": [
        "def remove_accentuation(text):\n",
        "    nfkd = unicodedata.normalize(\"NFKD\", text)\n",
        "    return \"\".join([c for c in nfkd if not unicodedata.combining(c)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "j-CJTdqBG8Ni"
      },
      "outputs": [],
      "source": [
        "def clean_text(text, stopwords_set=None):\n",
        "    if text is None:\n",
        "        return \"\"\n",
        "    text = text.lower()\n",
        "    text = remove_accentuation(text)\n",
        "    text = re.sub(r\"http\\S+|www\\S+|https\\S+\", \" \", text)\n",
        "    text = re.sub(r\"@\\w+\", \" \", text)\n",
        "    text = re.sub(r\"#\\w+\", \" \", text)\n",
        "    text = re.sub(r\"\\d+\", \" \", text)\n",
        "    text = text.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
        "    tokens = text.split()\n",
        "    if stopwords_set is not None:\n",
        "        tokens = [w for w in tokens if w not in stopwords_set]\n",
        "    return \" \".join(tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "TLOVgkmEHQJA"
      },
      "outputs": [],
      "source": [
        "def preprocess(series, stopwords_set=None):\n",
        "    return series.map(lambda x: clean_text(str(x), stopwords_set=stopwords_set))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_RDvOewsIV3U"
      },
      "source": [
        "## Tratamento e Rotulagem"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "F3El7ddkJd7T"
      },
      "outputs": [],
      "source": [
        "stopwords_pt = set(stopwords.words(\"portuguese\"))\n",
        "df[\"text_clean\"] = preprocess(df[\"text\"], stopwords_set=stopwords_pt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "-5tjIR4SKbAx"
      },
      "outputs": [],
      "source": [
        "categories = [\"homophobia\",\"obscene\",\"insult\",\"racism\",\"misogyny\",\"xenophobia\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "yubebEAHU8Ax"
      },
      "outputs": [],
      "source": [
        "vect = TfidfVectorizer(ngram_range=(1,2), min_df=5, max_df=0.9)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YAMI56tZJzYF"
      },
      "source": [
        "### Binária"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "SzEixfN_Jyzt"
      },
      "outputs": [],
      "source": [
        "df_binary = df.copy()\n",
        "df_binary[\"toxic_binary\"] = (df_binary[categories].sum(axis=1) > 0).astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "Ci0jBKfcKJty"
      },
      "outputs": [],
      "source": [
        "X_binary = df_binary[\"text_clean\"].values\n",
        "y_binary = df_binary[\"toxic_binary\"].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "r7egPXQfL63J"
      },
      "outputs": [],
      "source": [
        "X_train_bin, X_test_bin, y_train_bin, y_test_bin = train_test_split(\n",
        "    X_binary, y_binary, test_size=0.2, stratify=y_binary, random_state=SEED\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "HouJnb5_NYe5"
      },
      "outputs": [],
      "source": [
        "X_train_bin_tfidf = vect.fit_transform(X_train_bin)\n",
        "X_test_bin_tfidf  = vect.transform(X_test_bin)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OzucYWeGKMer"
      },
      "source": [
        "### Multilabel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "odEftwg1KkQM"
      },
      "outputs": [],
      "source": [
        "df_multil = df.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "pB3AXcgMKQys"
      },
      "outputs": [],
      "source": [
        "y_multil = df_multil[categories].apply(lambda col: (col > 0).astype(int)).values\n",
        "X_multil = df_multil[\"text_clean\"].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "Ij_PKyD0L-Ns"
      },
      "outputs": [],
      "source": [
        "X_train_ml, X_test_ml, y_train_ml, y_test_ml = train_test_split(\n",
        "    X_multil, y_multil, test_size=0.2, random_state=SEED\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "23FMbNA5NymN"
      },
      "outputs": [],
      "source": [
        "X_train_ml_tfidf = vect.fit_transform(X_train_ml)\n",
        "X_test_ml_tfidf  = vect.transform(X_test_ml)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vC4HXt91OsGr"
      },
      "source": [
        "## Execução e Avaliação"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "vtFPK5AzP1OI"
      },
      "outputs": [],
      "source": [
        "models = {\n",
        "    \"LogisticRegression\": LogisticRegression(max_iter=200, random_state=SEED, class_weight=\"balanced\"),\n",
        "    \"NaiveBayes\":        MultinomialNB(),\n",
        "    \"DecisionTree\":      DecisionTreeClassifier(random_state=SEED, class_weight=\"balanced\"),\n",
        "    \"RandomForest\":      RandomForestClassifier(n_estimators=100, random_state=SEED, class_weight=\"balanced\", n_jobs=-1),\n",
        "    \"KNN\":               KNeighborsClassifier(n_neighbors=5)\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "bB-2gkN4YGL8"
      },
      "outputs": [],
      "source": [
        "estimators = [(name, model) for name, model in models.items()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "sRSdib50V7YB"
      },
      "outputs": [],
      "source": [
        "def save_results_json(execution_type, results):\n",
        "  with open(f\"./results_{execution_type}.json\", \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(results, f, indent=4, ensure_ascii=False)\n",
        "  print(f\"Resultados de classificação {execution_type} salvos em results_{execution_type}.json\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A2kmFyeyQmKA"
      },
      "source": [
        "### Binária"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "o-wZoR4dO2ch"
      },
      "outputs": [],
      "source": [
        "def test_results_binary(name, y_test, y_pred, results):\n",
        "    acc  = accuracy_score(y_test, y_pred)\n",
        "    prec = precision_score(y_test, y_pred, zero_division=0)\n",
        "    rec  = recall_score(y_test, y_pred, zero_division=0)\n",
        "    f1   = f1_score(y_test, y_pred, zero_division=0)\n",
        "    cm   = confusion_matrix(y_test, y_pred).tolist()\n",
        "    print(f\"{name} — acc:{acc:.4f}, prec:{prec:.4f}, rec:{rec:.4f}, f1:{f1:.4f}\")\n",
        "    print(classification_report(y_test, y_pred))\n",
        "    results[name] = {\n",
        "        \"accuracy\": acc,\n",
        "        \"precision\": prec,\n",
        "        \"recall\": rec,\n",
        "        \"f1_score\": f1,\n",
        "        \"confusion_matrix\": cm\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "6-xyni26Owd9"
      },
      "outputs": [],
      "source": [
        "def run_models_binary(results, X_train, y_train, X_test, y_test):\n",
        "  for name, model in models.items():\n",
        "    print(f\"[Binária] Treinando modelo: {name}\")\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    test_results_binary(name, y_test, y_pred, results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pUr3FSO7QpcG"
      },
      "source": [
        "### Multilabel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "GXitchS-Qs0y"
      },
      "outputs": [],
      "source": [
        "def test_results_multilabel(name, y_test, y_pred, results):\n",
        "    acc  = accuracy_score(y_test, y_pred)\n",
        "    prec = precision_score(y_test, y_pred, average=\"macro\", zero_division=0)\n",
        "    rec  = recall_score(y_test, y_pred, average=\"macro\", zero_division=0)\n",
        "    f1   = f1_score(y_test, y_pred, average=\"macro\", zero_division=0)\n",
        "    cm   = [confusion_matrix(y_test[:,i], y_pred[:,i]).tolist() for i in range(y_test.shape[1])]\n",
        "    hm   = hamming_loss(y_test, y_pred)\n",
        "    print(f\"{name} multilabel — acc:{acc:.4f}, prec:{prec:.4f}, rec:{rec:.4f}, f1:{f1:.4f}\")\n",
        "    print(classification_report(y_test, y_pred, zero_division=0))\n",
        "    results[name] = {\n",
        "        \"accuracy\": acc,\n",
        "        \"precision_macro\": prec,\n",
        "        \"recall_macro\": rec,\n",
        "        \"f1_macro\": f1,\n",
        "        \"hamming_loss\": hm,\n",
        "        \"confusion_matrix_per_class\": cm\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "Rk6UzSh_RKLZ"
      },
      "outputs": [],
      "source": [
        "def run_models_multilabel(results, X_train, y_train, X_test, y_test):\n",
        "  for name, base_model in models.items():\n",
        "    print(f\"[Multilabel] Treinando modelo: {name}\")\n",
        "    ml_model = OneVsRestClassifier(base_model)\n",
        "    ml_model.fit(X_train, y_train)\n",
        "    y_pred_ml = ml_model.predict(X_test)\n",
        "    test_results_multilabel(name, y_test, y_pred_ml, results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-JTSE7-2YfAJ"
      },
      "source": [
        "### Ensemble Voting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "xOcDw5vmYqcR"
      },
      "outputs": [],
      "source": [
        "def ensemble_voting(execution_type, results, X_train, y_train, X_test, y_test):\n",
        "  print(f\"[{execution_type}] Treinando Voting Ensemble\")\n",
        "  voting = OneVsRestClassifier(VotingClassifier(estimators=estimators, voting=\"soft\", n_jobs=-1)) if execution_type == \"Multilabel\" else VotingClassifier(estimators=estimators, voting=\"soft\", n_jobs=-1)\n",
        "  voting.fit(X_train, y_train)\n",
        "  y_pred_v = voting.predict(X_test)\n",
        "  if execution_type == \"Multilabel\":\n",
        "    test_results_multilabel(\"VotingEnsemble\", y_test, y_pred_v, results)\n",
        "  else:\n",
        "    test_results_binary(\"VotingEnsemble\", y_test, y_pred_v, results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nZbfKNiiN5jS"
      },
      "source": [
        "## Treinamentos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7tLmunuxOQiF"
      },
      "source": [
        "### Binário"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hzrqIolNOJkq",
        "outputId": "57674064-b245-4fcd-8b31-e4b0170316b3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Binária] Treinando modelo: LogisticRegression\n",
            "LogisticRegression — acc:0.7426, prec:0.7065, rec:0.7115, f1:0.7090\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.77      0.77      0.77      2349\n",
            "           1       0.71      0.71      0.71      1851\n",
            "\n",
            "    accuracy                           0.74      4200\n",
            "   macro avg       0.74      0.74      0.74      4200\n",
            "weighted avg       0.74      0.74      0.74      4200\n",
            "\n",
            "[Binária] Treinando modelo: NaiveBayes\n",
            "NaiveBayes — acc:0.7086, prec:0.7209, rec:0.5527, f1:0.6257\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.70      0.83      0.76      2349\n",
            "           1       0.72      0.55      0.63      1851\n",
            "\n",
            "    accuracy                           0.71      4200\n",
            "   macro avg       0.71      0.69      0.69      4200\n",
            "weighted avg       0.71      0.71      0.70      4200\n",
            "\n",
            "[Binária] Treinando modelo: DecisionTree\n",
            "DecisionTree — acc:0.7045, prec:0.6486, rec:0.7191, f1:0.6820\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.76      0.69      0.72      2349\n",
            "           1       0.65      0.72      0.68      1851\n",
            "\n",
            "    accuracy                           0.70      4200\n",
            "   macro avg       0.70      0.71      0.70      4200\n",
            "weighted avg       0.71      0.70      0.71      4200\n",
            "\n",
            "[Binária] Treinando modelo: RandomForest\n",
            "RandomForest — acc:0.7350, prec:0.6930, rec:0.7158, f1:0.7042\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.77      0.75      0.76      2349\n",
            "           1       0.69      0.72      0.70      1851\n",
            "\n",
            "    accuracy                           0.73      4200\n",
            "   macro avg       0.73      0.73      0.73      4200\n",
            "weighted avg       0.74      0.73      0.74      4200\n",
            "\n",
            "[Binária] Treinando modelo: KNN\n",
            "KNN — acc:0.6195, prec:0.6341, rec:0.3231, f1:0.4281\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.62      0.85      0.71      2349\n",
            "           1       0.63      0.32      0.43      1851\n",
            "\n",
            "    accuracy                           0.62      4200\n",
            "   macro avg       0.62      0.59      0.57      4200\n",
            "weighted avg       0.62      0.62      0.59      4200\n",
            "\n",
            "[Binaria] Treinando Voting Ensemble\n",
            "VotingEnsemble — acc:0.7281, prec:0.6851, rec:0.7088, f1:0.6968\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.76      0.74      0.75      2349\n",
            "           1       0.69      0.71      0.70      1851\n",
            "\n",
            "    accuracy                           0.73      4200\n",
            "   macro avg       0.72      0.73      0.73      4200\n",
            "weighted avg       0.73      0.73      0.73      4200\n",
            "\n",
            "Resultados de classificação binaria salvos em results_binaria.json\n"
          ]
        }
      ],
      "source": [
        "results_bin = {}\n",
        "\n",
        "run_models_binary(results_bin, X_train_bin_tfidf, y_train_bin, X_test_bin_tfidf, y_test_bin)\n",
        "ensemble_voting(\"Binaria\", results_bin, X_train_bin_tfidf, y_train_bin, X_test_bin_tfidf, y_test_bin)\n",
        "\n",
        "save_results_json(\"binaria\", results_bin)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YX18B2fGVXFd"
      },
      "source": [
        "### Multilabel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K9XsES73Vbxw",
        "outputId": "85b55b85-cb87-42fb-a007-6a8b65f07dd6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Multilabel] Treinando modelo: LogisticRegression\n",
            "LogisticRegression multilabel — acc:0.5948, prec:0.3648, rec:0.6020, f1:0.4463\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.39      0.74      0.51        53\n",
            "           1       0.64      0.76      0.69      1304\n",
            "           2       0.52      0.69      0.59       857\n",
            "           3       0.18      0.50      0.27        22\n",
            "           4       0.25      0.47      0.33        97\n",
            "           5       0.21      0.45      0.29        31\n",
            "\n",
            "   micro avg       0.54      0.72      0.62      2364\n",
            "   macro avg       0.36      0.60      0.45      2364\n",
            "weighted avg       0.56      0.72      0.63      2364\n",
            " samples avg       0.30      0.32      0.30      2364\n",
            "\n",
            "[Multilabel] Treinando modelo: NaiveBayes\n",
            "NaiveBayes multilabel — acc:0.6262, prec:0.4330, rec:0.0944, f1:0.1403\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00        53\n",
            "           1       0.76      0.35      0.48      1304\n",
            "           2       0.84      0.18      0.30       857\n",
            "           3       0.00      0.00      0.00        22\n",
            "           4       1.00      0.03      0.06        97\n",
            "           5       0.00      0.00      0.00        31\n",
            "\n",
            "   micro avg       0.78      0.26      0.39      2364\n",
            "   macro avg       0.43      0.09      0.14      2364\n",
            "weighted avg       0.76      0.26      0.38      2364\n",
            " samples avg       0.13      0.11      0.12      2364\n",
            "\n",
            "[Multilabel] Treinando modelo: DecisionTree\n",
            "DecisionTree multilabel — acc:0.5219, prec:0.2911, rec:0.5025, f1:0.3512\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.34      0.70      0.46        53\n",
            "           1       0.59      0.69      0.64      1304\n",
            "           2       0.46      0.56      0.50       857\n",
            "           3       0.04      0.36      0.08        22\n",
            "           4       0.22      0.44      0.30        97\n",
            "           5       0.09      0.26      0.13        31\n",
            "\n",
            "   micro avg       0.47      0.63      0.54      2364\n",
            "   macro avg       0.29      0.50      0.35      2364\n",
            "weighted avg       0.51      0.63      0.56      2364\n",
            " samples avg       0.27      0.28      0.26      2364\n",
            "\n",
            "[Multilabel] Treinando modelo: RandomForest\n",
            "RandomForest multilabel — acc:0.6429, prec:0.5235, rec:0.2936, f1:0.3536\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.70      0.36      0.48        53\n",
            "           1       0.64      0.69      0.67      1304\n",
            "           2       0.69      0.39      0.50       857\n",
            "           3       0.08      0.05      0.06        22\n",
            "           4       0.62      0.21      0.31        97\n",
            "           5       0.40      0.06      0.11        31\n",
            "\n",
            "   micro avg       0.65      0.54      0.59      2364\n",
            "   macro avg       0.52      0.29      0.35      2364\n",
            "weighted avg       0.65      0.54      0.57      2364\n",
            " samples avg       0.26      0.24      0.25      2364\n",
            "\n",
            "[Multilabel] Treinando modelo: KNN\n",
            "KNN multilabel — acc:0.5936, prec:0.6541, rec:0.1303, f1:0.2137\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      0.15      0.25        53\n",
            "           1       0.68      0.19      0.29      1304\n",
            "           2       0.64      0.17      0.27       857\n",
            "           3       0.00      0.00      0.00        22\n",
            "           4       0.94      0.18      0.30        97\n",
            "           5       1.00      0.10      0.18        31\n",
            "\n",
            "   micro avg       0.67      0.18      0.28      2364\n",
            "   macro avg       0.65      0.13      0.21      2364\n",
            "weighted avg       0.67      0.18      0.28      2364\n",
            " samples avg       0.08      0.08      0.08      2364\n",
            "\n",
            "[Multilabel] Treinando Voting Ensemble\n",
            "VotingEnsemble multilabel — acc:0.6536, prec:0.6873, rec:0.3032, f1:0.3946\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.69      0.38      0.49        53\n",
            "           1       0.68      0.59      0.63      1304\n",
            "           2       0.69      0.39      0.50       857\n",
            "           3       0.40      0.09      0.15        22\n",
            "           4       0.66      0.22      0.33        97\n",
            "           5       1.00      0.16      0.28        31\n",
            "\n",
            "   micro avg       0.69      0.48      0.57      2364\n",
            "   macro avg       0.69      0.30      0.39      2364\n",
            "weighted avg       0.69      0.48      0.56      2364\n",
            " samples avg       0.23      0.21      0.22      2364\n",
            "\n",
            "Resultados de classificação multilabel salvos em results_multilabel.json\n"
          ]
        }
      ],
      "source": [
        "results_ml = {}\n",
        "\n",
        "run_models_multilabel(results_ml, X_train_ml_tfidf, y_train_ml, X_test_ml_tfidf, y_test_ml)\n",
        "ensemble_voting(\"Multilabel\", results_ml, X_train_ml_tfidf, y_train_ml, X_test_ml_tfidf, y_test_ml)\n",
        "\n",
        "save_results_json(\"multilabel\", results_ml)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
